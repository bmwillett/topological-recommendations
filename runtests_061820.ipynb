{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lib.data_class import *\n",
    "from models.main_models import *\n",
    "from models.baseline_models import *\n",
    "from lib.process_data import *\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "log = logging.getLogger(\"TR_logger\")\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "USE_DATA_SET = 'small'\n",
    "IC_DATA_DIR = {'micro':'./data/instacart_2017_05_01_micro/',\n",
    "               'tiny':'./data/instacart_2017_05_01_tiny/',\n",
    "               'small':'./data/instacart_2017_05_01_small/',\n",
    "               'medium':'./data/instacart_2017_05_01_medium/',\n",
    "               'full':'./data/instacart_2017_05_01/'}[USE_DATA_SET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data \n",
    "-> using hard-coded function for Instacart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data, product_data = instacart_process(data_dir=IC_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_dataset = DataSet(order_data, product_data)\n",
    "train_dataset, val_dataset, test_dataset = IC_dataset.test_train_val_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.38341705143868116, recall = 0.859337924555316, f1 = 0.4815422897327067, ndcg = 0.7542152040221292\n"
     ]
    }
   ],
   "source": [
    "lg_model = LGBoostModel()\n",
    "lg_model.fit(train_dataset)\n",
    "lg_model.find_threshold(val_dataset, pts=50, max=0.5)\n",
    "lg_model.accuracy_test(test_dataset)\n",
    "print(\"precision = {}, recall = {}, f1 = {}, ndcg = {}\".format(lg_model.prec, lg_model.rec, lg_model.f1, lg_model.ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent+feature-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating LFNetModel...\n",
      "fitting network...\n",
      "Epoch 1/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.7258\n",
      "Epoch 2/20\n",
      "90219/90219 [==============================] - 3s 30us/step - loss: 0.3774\n",
      "Epoch 3/20\n",
      "90219/90219 [==============================] - 3s 31us/step - loss: 0.2789\n",
      "Epoch 4/20\n",
      "90219/90219 [==============================] - 3s 34us/step - loss: 0.2380\n",
      "Epoch 5/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.2227\n",
      "Epoch 6/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.2159: 0s - loss: 0.2\n",
      "Epoch 7/20\n",
      "90219/90219 [==============================] - 3s 31us/step - loss: 0.2091\n",
      "Epoch 8/20\n",
      "90219/90219 [==============================] - 3s 30us/step - loss: 0.2036\n",
      "Epoch 9/20\n",
      "90219/90219 [==============================] - 3s 34us/step - loss: 0.2016\n",
      "Epoch 10/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.2003: 0s \n",
      "Epoch 11/20\n",
      "90219/90219 [==============================] - 3s 31us/step - loss: 0.1989\n",
      "Epoch 12/20\n",
      "90219/90219 [==============================] - 3s 33us/step - loss: 0.1996\n",
      "Epoch 13/20\n",
      "90219/90219 [==============================] - 3s 31us/step - loss: 0.1988\n",
      "Epoch 14/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.1992\n",
      "Epoch 15/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.1982\n",
      "Epoch 16/20\n",
      "90219/90219 [==============================] - 3s 28us/step - loss: 0.1986\n",
      "Epoch 17/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.1985\n",
      "Epoch 18/20\n",
      "90219/90219 [==============================] - 3s 33us/step - loss: 0.1978\n",
      "Epoch 19/20\n",
      "90219/90219 [==============================] - 3s 31us/step - loss: 0.1972\n",
      "Epoch 20/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.1980\n",
      "precision = 0.4100245319554408, recall = 0.806692046547119, f1 = 0.48747338814408503, ndcg = 0.7752690948158483\n"
     ]
    }
   ],
   "source": [
    "# train latent models\n",
    "user_encoder = UserAEM()\n",
    "user_encoder.fit(train_dataset, verbose=0)\n",
    "product_encoder = HybridProductLatentModel()\n",
    "product_encoder.fit(train_dataset, verbose=0)\n",
    "\n",
    "# train main model\n",
    "lfn_model = LFNetModel(user_latent_model=user_encoder, product_latent_model=product_encoder)\n",
    "lfn_model.fit(train_dataset, epochs=20)\n",
    "lfn_model.find_threshold(val_dataset, pts=10, max=0.5)\n",
    "lfn_model.accuracy_test(test_dataset)\n",
    "print(\"precision = {}, recall = {}, f1 = {}, ndcg = {}\".format(lfn_model.prec, lfn_model.rec, lfn_model.f1, lfn_model.ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological latent+feature-net model (without bypass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # train latent models\n",
    "# user_encoder = UserAEM()\n",
    "# user_encoder.fit(train_dataset, verbose=0)\n",
    "# product_encoder = HybridProductLatentModel()\n",
    "# product_encoder.fit(train_dataset, verbose=0)\n",
    "\n",
    "# # train main model\n",
    "# tlfn_model = TLFNetModel(user_latent_model=user_encoder, product_latent_model=product_encoder, bypass=False)\n",
    "# tlfn_model.fit(train_dataset, epochs=20)\n",
    "# tlfn_model.find_threshold(val_dataset, pts=10, max=0.5)\n",
    "# tlfn_model.accuracy_test(test_dataset)\n",
    "# print(\"precision = {}, recall = {}, f1 = {}, ndcg = {}\".format(tlfn_model.prec, tlfn_model.rec, tlfn_model.f1, tlfn_model.ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological latent+feature-net model (with bypass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # train latent models\n",
    "# user_encoder = UserAEM()\n",
    "# user_encoder.fit(train_dataset, verbose=0)\n",
    "# product_encoder = HybridProductLatentModel()\n",
    "# product_encoder.fit(train_dataset, verbose=0)\n",
    "\n",
    "# # train main model\n",
    "# tlfnb_model = TLFNetModel(user_latent_model=user_encoder, product_latent_model=product_encoder)\n",
    "# tlfnb_model.fit(train_dataset, epochs=20)\n",
    "# tlfnb_model.find_threshold(val_dataset, pts=10, max=0.5)\n",
    "# tlfnb_model.accuracy_test(test_dataset)\n",
    "# print(\"precision = {}, recall = {}, f1 = {}, ndcg = {}\".format(tlfnb_model.prec, tlfnb_model.rec, tlfnb_model.f1, tlfnb_model.ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-topological latent+feature-net model (without bypass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating TULFNetModel...\n",
      "reducing from X_train_user.shape=(90219, 36) to X_train_user_red.shape=(1443, 36) for mapping...\n",
      "fitting mapper...\n",
      "--->getting latent space rep...\n",
      "------> fitting PCA to data of shape (1443, 36)...\n",
      "--->creating mapper graphs...\n",
      "------> creating projection components...\n",
      "---------> on component 1/5...\n",
      "---------> on component 2/5...\n",
      "---------> on component 3/5...\n",
      "---------> on component 4/5...\n",
      "---------> on component 5/5...\n",
      "------> entering parallelization...\n",
      "------> exiting parallelization after 0.3906363560000159 seconds\n",
      "--->assigning train points to graph node bins...\n",
      "expanded from self.X_map_red.shape=(1443, 84) to self.X_map.shape=(90219, 84)...\n",
      "combining X_train.shape=(90219, 50) and self.X_map.shape=(90219, 84)...\n",
      "obtained self.X_map.shape=(90219, 134)\n",
      "created mapper encoding of size self.X_map.shape[1]\n",
      "fitting network...\n",
      "Epoch 1/20\n",
      "90219/90219 [==============================] - 4s 44us/step - loss: 0.4170\n",
      "Epoch 2/20\n",
      "90219/90219 [==============================] - 4s 40us/step - loss: 0.2865\n",
      "Epoch 3/20\n",
      "90219/90219 [==============================] - 3s 37us/step - loss: 0.2359\n",
      "Epoch 4/20\n",
      "90219/90219 [==============================] - 3s 30us/step - loss: 0.2112\n",
      "Epoch 5/20\n",
      "90219/90219 [==============================] - 3s 33us/step - loss: 0.2037\n",
      "Epoch 6/20\n",
      "90219/90219 [==============================] - 3s 32us/step - loss: 0.1999\n",
      "Epoch 7/20\n",
      "90219/90219 [==============================] - 3s 36us/step - loss: 0.1993\n",
      "Epoch 8/20\n",
      "90219/90219 [==============================] - 3s 37us/step - loss: 0.1991\n",
      "Epoch 9/20\n",
      "90219/90219 [==============================] - 3s 36us/step - loss: 0.1975\n",
      "Epoch 10/20\n",
      "90219/90219 [==============================] - 3s 36us/step - loss: 0.1995\n",
      "Epoch 11/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.1978\n",
      "Epoch 12/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.1993\n",
      "Epoch 13/20\n",
      "90219/90219 [==============================] - 3s 36us/step - loss: 0.1974\n",
      "Epoch 14/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.1978\n",
      "Epoch 15/20\n",
      "90219/90219 [==============================] - 3s 36us/step - loss: 0.1984\n",
      "Epoch 16/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.1987\n",
      "Epoch 17/20\n",
      "90219/90219 [==============================] - 4s 39us/step - loss: 0.1981\n",
      "Epoch 18/20\n",
      "90219/90219 [==============================] - 4s 42us/step - loss: 0.1979\n",
      "Epoch 19/20\n",
      "90219/90219 [==============================] - 4s 42us/step - loss: 0.1992\n",
      "Epoch 20/20\n",
      "90219/90219 [==============================] - 3s 35us/step - loss: 0.1977\n"
     ]
    }
   ],
   "source": [
    "# train latent models\n",
    "user_encoder = UserAEM()\n",
    "user_encoder.fit(train_dataset, verbose=0)\n",
    "product_encoder = HybridProductLatentModel()\n",
    "product_encoder.fit(train_dataset, verbose=0)\n",
    "\n",
    "# train main model\n",
    "tulfnb_model = TULFNetModel(user_latent_model=user_encoder, product_latent_model=product_encoder)\n",
    "tulfnb_model.fit(train_dataset, epochs=20)\n",
    "tulfnb_model.find_threshold(val_dataset, pts=10, max=0.5)\n",
    "tulfnb_model.accuracy_test(test_dataset)\n",
    "print(\"precision = {}, recall = {}, f1 = {}, ndcg = {}\".format(tulfnb_model.prec, tulfnb_model.rec, tulfnb_model.f1, tulfnb_model.ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fn, res_lfn = {}, {}\n",
    "num_tries = 3\n",
    "\n",
    "models = [lg_model,\n",
    "          lfn_model,  \n",
    "          tulfnb_model]\n",
    "\n",
    "res=[{}, {}, {}]\n",
    "for i in range(10):\n",
    "    for r in res:\n",
    "        r[i]= np.zeros(4)    \n",
    "    for j in range(num_tries):\n",
    "        test_adv = test_dataset.make_adversarial(num_switches=i+1)\n",
    "        for r, model in zip(res,models):\n",
    "            model.accuracy_test(test_adv)\n",
    "            r[i] += np.array([model.prec, model.rec, model.f1, model.ndcg])/num_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m=3\n",
    "lg_data=[res[0][i][m] for i in range(10)]\n",
    "lfn_data=[res[1][i][m] for i in range(10)]\n",
    "tulfnb_data=[res[2][i][m] for i in range(10)]\n",
    "\n",
    "\n",
    "plt.plot(list(range(1,11)),lg_data, label='LG model')\n",
    "plt.plot(list(range(1,11)),lfn_data, label='LFN model')\n",
    "plt.plot(list(range(1,11)),tulfnb_data, label='TU-LFN model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROC(model, test_dataset, num_pts=10):\n",
    "    thresholds = np.linspace(0,1,num_pts)\n",
    "\n",
    "    preds, test_labels, prior_orders = model.predict(test_dataset, getdf=True)\n",
    "\n",
    "    user_true = {}\n",
    "    user_pred = {}\n",
    "    user_all = {}\n",
    "    for i,row in enumerate(prior_orders.itertuples()):\n",
    "        uid = row.user_id\n",
    "        pid = row.product_id\n",
    "        if uid not in user_true:\n",
    "            user_true[uid], user_pred[uid], user_all[uid]  = [], {threshold:[] for threshold in thresholds}, 0\n",
    "        user_all[uid]+=1\n",
    "        if test_labels[i] == 1:\n",
    "            user_true[uid].append(pid)\n",
    "        for threshold in thresholds:\n",
    "            if preds[i] > threshold:\n",
    "                user_pred[uid][threshold].append(pid)\n",
    "\n",
    "    tprs, tnrs = {threshold:[] for threshold in thresholds}, {threshold:[] for threshold in thresholds}\n",
    "    for uid in user_true:\n",
    "        trues = set(user_true[uid])\n",
    "        tot = user_all[uid]\n",
    "        for threshold in thresholds:\n",
    "            preds = set(user_pred[uid][threshold])\n",
    "\n",
    "            tp = len(trues.intersection(preds))\n",
    "            fp = len(preds) - tp\n",
    "            fn = len(trues) - tp\n",
    "            tn = tot-fp-fn-tp\n",
    "\n",
    "            tpr = tp/(tp+fn) if tp+fn>0 else 1\n",
    "            tnr = tn/(tn+fp) if tn+fp>0 else 1\n",
    "        \n",
    "            tprs[threshold].append(tpr)\n",
    "            tnrs[threshold].append(1-tnr)\n",
    "\n",
    "    out = np.transpose(np.array([[np.mean(tprs[threshold]),np.mean(tnrs[threshold])] for threshold in thresholds]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_roc = getROC(lg_model,test_dataset,num_pts=20)\n",
    "lfn_roc = getROC(lfn_model,test_dataset,num_pts=20)\n",
    "tulfnb_roc = getROC(tulfnb_model,test_dataset,num_pts=20)\n",
    "plt.plot(lg_roc[1],lg_roc[0])\n",
    "plt.plot(lfn_roc[1],lfn_roc[0])\n",
    "plt.plot(tulfnb_roc[1],tulfnb_roc[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
